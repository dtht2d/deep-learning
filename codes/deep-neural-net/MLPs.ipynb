{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtht2d/deep-learning/blob/main/codes/deep-neural-net/MLPs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%autosave 30"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kfiqWesDJp0v",
        "outputId": "aadf89b1-8e24-443f-8a79-3c78c6597dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.notebook.set_autosave_interval(30000)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autosaving every 30 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Objective**\n",
        "- Perform Correlation Analysis and Linear Regression on a Dataset\n",
        "- Compare the Performance of Different Types of MLP Neural Networks\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "34VqEBFnJz50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Background:**\n",
        "### **a. Intuiety understanding of correlation analysis in machine learning:**\n",
        "\n",
        " **Definition:** a statistical technique used to measure the strength of the association between two or more variables. It helps to identify the nature and extent of the relationship between the variables. \n",
        "\n",
        " **Methods**: The most commonly used method for correlation analysis is the Pearson correlation coefficient, which measures the linear relationship between two variables. Other methods include the Spearman and Kendall correlation coefficients, which measure the association between variables without assuming a linear relationship.\n",
        "\n",
        "**Pros:**\n",
        "  \t- Identifies relationships between variables. \n",
        "    - Useful for feature selection and dimensionality reduction.\n",
        "    - Easy to implement.\n",
        "\n",
        " **Cons:**\n",
        "  \t- Assumes linearity (in the case of Pearson correlation coefficient). \n",
        "    - Cannot determine causality.\n",
        "    - May be influenced by outliers."
      ],
      "metadata": {
        "id": "hMBV391-PQuC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **b. Multi-Layer Perceptron (MLP) neural network:**\n",
        "\n",
        "**Definition:** artificial neural network (ANN) that consist of multiple layers of interconnected nodes (neurons) used for supervised learning tasks such as classification and regression. The network learns to map inputs to outputs by adjusting weights through an optimization algorithm during training, allowing it to approximate complex non-linear functions.\n",
        "\n",
        "**Intuitive way to think about MLPs:** function approximators\n",
        "\n",
        "By learning to map inputs to outputs, the network is essentially learning a function that approximates the true underlying relationship between the inputs and outputs. The hidden layers allow the network to learn complex, non-linear functions that would be difficult or impossible to express using simpler models.\n",
        "![Flow-of-the-training-process-of-MLP-networks.png](data:image/png;base64,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)\n",
        "\n",
        "source :https://www.researchgate.net/figure/Flow-of-the-training-process-of-MLP-networks_fig4_250071596\n"
      ],
      "metadata": {
        "id": "5fZC0cIdSUtK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **2. Methods:**"
      ],
      "metadata": {
        "id": "lXePevWqPHTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install package"
      ],
      "metadata": {
        "id": "h62p3zq_VZDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas"
      ],
      "metadata": {
        "id": "bvahQU_qVbls",
        "outputId": "3d6bc364-2e5c-4af2-adf4-a92606edd7b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (1.4.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy"
      ],
      "metadata": {
        "id": "7EW9IJjuVfrc",
        "outputId": "c3c40fa5-d9df-46c5-b337-75de1fcf8ae4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib"
      ],
      "metadata": {
        "id": "e53g9uXNVoEZ",
        "outputId": "90d6f1e6-a7c9-4fa5-e508-71023797e8a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (3.7.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (23.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (5.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (4.39.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn"
      ],
      "metadata": {
        "id": "EElQsTctYWdg",
        "outputId": "845463fb-1882-428c-f5cb-e113ea3793ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2955 sha256=7fe811be489f2d3bab719ced274d041e0675e393b837df603a57ccf9ad3ced89\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/e0/3d/9d0c2020c44a519b9f02ab4fa6d2a4a996c98d79ab2f569fa1\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "sdmxzgrxj5KU",
        "outputId": "e08a4793-5ece-4b9c-a5ca-f4e58833c93e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (2.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.53.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.7)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow) (67.6.1)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow) (0.0.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (6.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import library "
      ],
      "metadata": {
        "id": "7d_MtCgFVtiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "SchlKir-VwSt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data"
      ],
      "metadata": {
        "id": "cgelqJrWVQZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9hFWn3R0VVGV",
        "outputId": "c7cec862-eebb-49a7-cc4f-03eb4c81de30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/deep-learning/bodyfat.csv\"\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "X = df.iloc[:, 2:].to_numpy()\n",
        "y = df['BodyFat'].to_numpy()\n",
        "#print X to check features number and y length\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "-hxwd-k4WYg6",
        "outputId": "5b104473-06b4-4ab7-cfd1-8886feedea6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(252, 13)\n",
            "(252,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**A- Correlation Analysis and Linear Regression on a Dataset**\n",
        "1. Calculate the correlation coefficient of each input feature with the output using the corrcoef function: corrcoef(X(i,:),T), i=1,2,…13.(\n",
        "2. Identify the input features that have a higher correlation with the output and select them for linear regression.\n",
        "3. Build a linear regression model using the selected input features and report the model coefficients.\n",
        "4. Split the dataset into training and testing sets, using the first half of the samples for training and the second half for testing.\n",
        "5. Train the linear regression model on the training set and evaluate its performance on the testing set by calculating the mean squared error (MSE).\n",
        "6. Report the MSE as the goodness of fit (loss function) measure to evaluate the performance of the linear regression model.\n"
      ],
      "metadata": {
        "id": "8EvZscDKOhav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# Find correlation coefficient of each input with the output\n",
        "correlations = np.array([np.corrcoef(X[:, i], y)[0, 1] for i in range(X.shape[1])])\n",
        "print(\"Correlation between each input and output:\", correlations)\n",
        "\n",
        "# Select inputs with highest correlation for linear regression\n",
        "selected_inputs = np.argsort(np.abs(correlations))[::-1][:2]  # Select top 2 inputs\n",
        "X_selected = X[:, selected_inputs]\n",
        "\n",
        "# Train linear regression model on first half of samples\n",
        "n_samples = X_selected.shape[0]\n",
        "n_half = n_samples // 2\n",
        "X_train, y_train = X_selected[:n_half], y[:n_half]\n",
        "model = LinearRegression().fit(X_train, y_train)\n",
        "\n",
        "# Test linear regression model on second half of samples\n",
        "X_test, y_test = X_selected[n_half:], y[n_half:]\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate mean squared error (MSE) as goodness of fit measure\n",
        "print(f\"Mean squared error: {mse:.2f}\")\n"
      ],
      "metadata": {
        "id": "U1kqsE9DX9nK",
        "outputId": "21359e60-30d0-4223-f890-ac8ac4c28673",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation between each input and output: [ 0.29145844  0.612414   -0.08949538  0.49059185  0.70262034  0.81343228\n",
            "  0.62520092  0.55960753  0.50866524  0.26596977  0.49327113  0.3613869\n",
            "  0.34657486]\n",
            "Mean squared error: 22.09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create IDs for each correlation\n",
        "correlation_ids = np.arange(len(correlations))\n",
        "\n",
        "# Sort correlations and their IDs in descending order\n",
        "sorted_indices = np.argsort(correlations)[::-1]\n",
        "sorted_correlations = correlations[sorted_indices]\n",
        "sorted_ids = correlation_ids[sorted_indices]\n",
        "\n",
        "# Print sorted correlations and their IDs\n",
        "for i in range(len(sorted_correlations)):\n",
        "    print(f\"Input variables ID: {sorted_ids[i]}, Correlation: {sorted_correlations[i]}\")\n"
      ],
      "metadata": {
        "id": "6knPDnf0VIL1",
        "outputId": "9d20fa82-cce5-48ed-87e1-66aae429a308",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input variables ID: 5, Correlation: 0.8134322847810496\n",
            "Input variables ID: 4, Correlation: 0.7026203388938652\n",
            "Input variables ID: 6, Correlation: 0.6252009175086634\n",
            "Input variables ID: 1, Correlation: 0.6124140022026479\n",
            "Input variables ID: 7, Correlation: 0.55960753199409\n",
            "Input variables ID: 8, Correlation: 0.5086652428854682\n",
            "Input variables ID: 10, Correlation: 0.49327112589161576\n",
            "Input variables ID: 3, Correlation: 0.4905918534410405\n",
            "Input variables ID: 11, Correlation: 0.36138690319971933\n",
            "Input variables ID: 12, Correlation: 0.3465748645265861\n",
            "Input variables ID: 0, Correlation: 0.29145844013522215\n",
            "Input variables ID: 9, Correlation: 0.2659697703063733\n",
            "Input variables ID: 2, Correlation: -0.08949537985440177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Interpretation of correlation coefficients:**\n",
        "\n",
        "*Positive correlation:* A positive correlation between two variables means both the variables move in the same direction. An increase in one variable leads to an increase in the other variable and vice versa.\n",
        "\n",
        "*Negative correlation:* A negative correlation between two variables means that the variables move in opposite directions. An increase in one variable leads to a decrease in the other variable and vice versa.\n",
        "\n",
        "*Weak/Zero correlation:* No correlation exists when one variable does not affect the other.\n"
      ],
      "metadata": {
        "id": "k45Gyv6FdFgu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Observation:**\n",
        "\n",
        "- Input variables 2, 5, 6, and 7 have relatively high positive correlation coefficients with the output variable, indicating a strong positive linear relationship between these variables. \n",
        "- Input variables 8, 10, 3, 11, 12 have moderate positive correlation coefficients with the output variable.\n",
        "- Input variables 0, 9 and 2 have relatively low correlation coefficients with the output variable, indicating a weak linear relationship.\n",
        "\n",
        "The MSE is 22.0869, which means that on average, the predicted values of the output variable are off by 22 units squared."
      ],
      "metadata": {
        "id": "RKNukfoIfVWy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "9gLDHq5lVHMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **B- Compare the Performance of Different Types of MLP Neural Networks**\n",
        "Use different types of MLP neural nets on all the input features dimensionalities. For each requested task, and retrain the neural network model at hand 10 times and report on both mean and variance on training and validation MSEs as follows: For each requested task, reset and retrain the neural network model at hand 10 times and report on both mean and variance on training and validation MSEs as follows:\n",
        "1. Create a simple 10-node one hidden layer regression MLP. Use the network with its default settings except for training/validation/test data partitioning ratios, which you shall set to 80%, 20%, and 0 % respectively. Find the mean and variance of MSEs for training and validation portions of the dataset from the 10 training repetitions\n",
        "2. Change the network’s hidden layer size to 2 nodes and then to 50 nodes, with training and validation ratios set to 30% and 70%, and then find the mean and variance of MSEs for training and validation portions of the dataset from the 10 training repetitions (again with random model initializations).\n",
        "3. For the 50-node model, have regularization (weight decay) set at 0.1 and 0.5 and the find mean and variance of MSEs for training and validation portions of the dataset from the 10 repetitions for each case."
      ],
      "metadata": {
        "id": "Mr_9C6vcOzfP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Assessing Performance of a Simple 10-Node MLP with Default Settings on a Regression Task using MSE:**\n",
        "**Task**: \n",
        "- Create a simple 10-node one hidden layer regression MLP. Use the network with its default settings except for training/validation/test data partitioning ratios, which we shall set to 80%, 20%, and 0 % respectively. \n",
        "- Find the mean and variance of MSEs for training and validation portions of the dataset from the 10 training repetitions\n",
        "\n",
        "**Purpose:**\n",
        "The purpose of this task is to evaluate the performance of a simple neural network with one hidden layer and 10 nodes for regression tasks. By partitioning the data into training and validation sets and performing multiple training repetitions with random initializations, we can get an idea of the mean and variance of the model's performance on both the training and validation data. This helps us understand whether the model is overfitting or underfitting, and whether it is performing well enough to be used for predicting new data."
      ],
      "metadata": {
        "id": "CnlDuSvDixIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Assuming X_train and y_train are the input features and target variable respectively\n",
        "# Splitting the dataset into training (80%) and validation (20%) sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Creating a simple 10-node one hidden layer regression MLP using Keras\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(10, input_shape=(X_train.shape[1],), activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Defining the number of times to reset and retrain the model\n",
        "num_repetitions = 10\n",
        "\n",
        "# Creating arrays to store the MSEs of the 10 training repetitions\n",
        "train_mses = np.zeros(num_repetitions)\n",
        "val_mses = np.zeros(num_repetitions)\n",
        "\n",
        "# Resetting and retraining the model 10 times\n",
        "for i in range(num_repetitions):\n",
        "    print('Training repetition', i+1)\n",
        "    \n",
        "    # Resetting the model\n",
        "    model.reset_states()\n",
        "    \n",
        "    # Training the model\n",
        "    history = model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), verbose=0)\n",
        "    \n",
        "    # Storing the MSEs for the training and validation sets\n",
        "    train_mses[i] = history.history['loss'][-1]\n",
        "    val_mses[i] = history.history['val_loss'][-1]\n",
        "\n",
        "# Finding the mean and variance of MSEs for training and validation portions of the dataset\n",
        "train_mse_mean = np.mean(train_mses)\n",
        "train_mse_var = np.var(train_mses)\n",
        "val_mse_mean = np.mean(val_mses)\n",
        "val_mse_var = np.var(val_mses)\n",
        "\n",
        "# Printing the results\n",
        "print('Training MSE mean:', train_mse_mean)\n",
        "print('Training MSE variance:', train_mse_var)\n",
        "print('Validation MSE mean:', val_mse_mean)\n",
        "print('Validation MSE variance:', val_mse_var)\n"
      ],
      "metadata": {
        "id": "897WeJABJy83",
        "outputId": "ddc02248-8a14-46d3-860b-654a9ce8232f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training repetition 1\n",
            "Training repetition 2\n",
            "Training repetition 3\n",
            "Training repetition 4\n",
            "Training repetition 5\n",
            "Training repetition 6\n",
            "Training repetition 7\n",
            "Training repetition 8\n",
            "Training repetition 9\n",
            "Training repetition 10\n",
            "Training MSE mean: 23.45686779022217\n",
            "Training MSE variance: 17.679434921008983\n",
            "Validation MSE mean: 25.214801216125487\n",
            "Validation MSE variance: 20.47563911104739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:** \n",
        "- The mean MSE for the training data is 23.4569 and for the validation data is 25.2148. This means that on average, the model's performance on the training data is slightly better than on the validation data. \n",
        "- The variance of the MSEs for the training data is 17.6794, which indicates that the model's performance on the training data varies quite a bit from repetition to repetition. Similarly, the variance of the MSEs for the validation data is 20.4756, which indicates that the model's performance on the validation data also varies quite a bit from repetition to repetition.\n",
        "\n",
        "- The variance of the MSEs for the training data is much lower than the variance of the MSEs for the validation data, this means the model is overfitting to the training data. \n"
      ],
      "metadata": {
        "id": "MM-dqkE5mdnV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. 10-Node MLP**"
      ],
      "metadata": {
        "id": "XfHDr-ENn5gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Assuming X_train and y_train are the input features and target variable respectively\n",
        "# Splitting the dataset into training (70%) and validation (30%) sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Creating a simple 2-node one hidden layer regression MLP using Keras\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(2, input_shape=(X_train.shape[1],), activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Defining the number of times to reset and retrain the model\n",
        "num_repetitions = 10\n",
        "\n",
        "# Creating arrays to store the MSEs of the 10 training repetitions\n",
        "train_mses = np.zeros(num_repetitions)\n",
        "val_mses = np.zeros(num_repetitions)\n",
        "\n",
        "# Resetting and retraining the model 10 times\n",
        "for i in range(num_repetitions):\n",
        "    print('Training repetition', i+1)\n",
        "    \n",
        "    # Resetting the model\n",
        "    model.reset_states()\n",
        "    \n",
        "    # Training the model\n",
        "    history = model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), verbose=0)\n",
        "    \n",
        "    # Storing the MSEs for the training and validation sets\n",
        "    train_mses[i] = history.history['loss'][-1]\n",
        "    val_mses[i] = history.history['val_loss'][-1]\n",
        "\n",
        "# Finding the mean and variance of MSEs for training and validation portions of the dataset\n",
        "train_mse_mean = np.mean(train_mses)\n",
        "train_mse_var = np.var(train_mses)\n",
        "val_mse_mean = np.mean(val_mses)\n",
        "val_mse_var = np.var(val_mses)\n",
        "\n",
        "# Printing the results\n",
        "print('Training MSE mean:', train_mse_mean)\n",
        "print('Training MSE variance:', train_mse_var)\n",
        "print('Validation MSE mean:', val_mse_mean)\n",
        "print('Validation MSE variance:', val_mse_var)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oo5d99QjoTEK",
        "outputId": "fb09b850-5ff9-4dfb-ea68-8a08d535ef65"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training repetition 1\n",
            "Training repetition 2\n",
            "Training repetition 3\n",
            "Training repetition 4\n",
            "Training repetition 5\n",
            "Training repetition 6\n",
            "Training repetition 7\n",
            "Training repetition 8\n",
            "Training repetition 9\n",
            "Training repetition 10\n",
            "Training MSE mean: 397.96485290527346\n",
            "Training MSE variance: 1828.8022540977315\n",
            "Validation MSE mean: 372.17259826660154\n",
            "Validation MSE variance: 1788.5181803813298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "- The model is overfitting the training data since the training MSE mean is significantly larger than the validation MSE mean. \n",
        "- This suggests that the model is performing well on the training set but not generalizing well to new data, as evidenced by the larger validation MSE. - The variance in both the training and validation MSEs suggests that the performance of the model varies widely across the 10 repetitions, which may indicate instability or sensitivity to initial conditions\n",
        "→ The model may not be performing well enough to be used for predicting new data, and further adjustments or improvements may be necessary."
      ],
      "metadata": {
        "id": "7kzlD6Jspjsg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. 50-node with regularization (weight decay) set at 0.1 and 0.5**"
      ],
      "metadata": {
        "id": "f81rXTUoq38X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Assuming X_train and y_train are the input features and target variable respectively\n",
        "# Splitting the dataset into training (70%) and validation (30%) sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Creating a 50-node one hidden layer regression MLP using Keras with weight decay set to 0.1\n",
        "model_1 = keras.Sequential([\n",
        "    keras.layers.Dense(50, input_shape=(X_train.shape[1],), activation='relu', kernel_regularizer=keras.regularizers.l2(0.1)),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compiling the model\n",
        "model_1.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Defining the number of times to reset and retrain the model\n",
        "num_repetitions = 10\n",
        "\n",
        "# Creating arrays to store the MSEs of the 10 training repetitions\n",
        "train_mses_1 = np.zeros(num_repetitions)\n",
        "val_mses_1 = np.zeros(num_repetitions)\n",
        "\n",
        "# Resetting and retraining the model 10 times\n",
        "for i in range(num_repetitions):\n",
        "    print('Training repetition', i+1)\n",
        "    \n",
        "    # Resetting the model\n",
        "    model_1.reset_states()\n",
        "    \n",
        "    # Training the model\n",
        "    history_1 = model_1.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), verbose=0)\n",
        "    \n",
        "    # Storing the MSEs for the training and validation sets\n",
        "    train_mses_1[i] = history_1.history['loss'][-1]\n",
        "    val_mses_1[i] = history_1.history['val_loss'][-1]\n",
        "\n",
        "# Finding the mean and variance of MSEs for training and validation portions of the dataset\n",
        "train_mse_mean_1 = np.mean(train_mses_1)\n",
        "train_mse_var_1 = np.var(train_mses_1)\n",
        "val_mse_mean_1 = np.mean(val_mses_1)\n",
        "val_mse_var_1 = np.var(val_mses_1)\n",
        "\n",
        "# Creating a 50-node one hidden layer regression MLP using Keras with weight decay set to 0.5\n",
        "model_2 = keras.Sequential([\n",
        "    keras.layers.Dense(50, input_shape=(X_train.shape[1],), activation='relu', kernel_regularizer=keras.regularizers.l2(0.5)),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compiling the model\n",
        "model_2.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Creating arrays to store the MSEs of the 10 training repetitions\n",
        "train_mses_2 = np.zeros(num_repetitions)\n",
        "val_mses_2 = np.zeros(num_repetitions)\n",
        "\n",
        "# Resetting and retraining the model 10 times\n",
        "for i in range(num_repetitions):\n",
        "    print('Training repetition', i+1)\n",
        "    \n",
        "    # Resetting the model\n",
        "    model_2.reset_states()\n",
        "    \n",
        "    # Training the model\n",
        "    history_2 = model_2.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), verbose=0)\n",
        "    \n",
        "    # Storing the MSEs for the training and validation sets\n",
        "    train_mses_2[i] = history_2.history['loss'][-1]\n",
        "    val_mses_2[i] = history_2.history['val_loss'][-1]\n",
        "\n",
        "# Finding the mean and variance of MSEs for training and validation portions of the dataset\n",
        "# Finding the mean and variance of MSEs for training and validation portions of the dataset for each model\n",
        "train_mse_mean_1 = np.mean(train_mses_1)\n",
        "train_mse_var_1 = np.var(train_mses_1)\n",
        "val_mse_mean_1 = np.mean(val_mses_1)\n",
        "val_mse_var_1 = np.var(val_mses_1)\n",
        "\n",
        "train_mse_mean_2 = np.mean(train_mses_2)\n",
        "train_mse_var_2 = np.var(train_mses_2)\n",
        "val_mse_mean_2 = np.mean(val_mses_2)\n",
        "val_mse_var_2 = np.var(val_mses_2)\n",
        "\n",
        "# Printing the results for model 1\n",
        "print('Model 1 (weight decay = 0.1)')\n",
        "print('Training MSE mean:', train_mse_mean_1)\n",
        "print('Training MSE variance:', train_mse_var_1)\n",
        "print('Validation MSE mean:', val_mse_mean_1 )\n",
        "print('Validation MSE variance:', val_mse_var_1)\n",
        "\n",
        "# Printing the results for model 2\n",
        "print('Model 1 (weight decay = 0.5)')\n",
        "print('Training MSE mean:', train_mse_mean_2)\n",
        "print('Training MSE variance:', train_mse_var_2)\n",
        "print('Validation MSE mean:', val_mse_mean_2)\n",
        "print('Validation MSE variance:', val_mse_var_2)\n"
      ],
      "metadata": {
        "id": "YyihGKW_rAQ6",
        "outputId": "e1e4ce9f-b6a9-419c-c5d3-7320dc943f8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training repetition 1\n",
            "Training repetition 2\n",
            "Training repetition 3\n",
            "Training repetition 4\n",
            "Training repetition 5\n",
            "Training repetition 6\n",
            "Training repetition 7\n",
            "Training repetition 8\n",
            "Training repetition 9\n",
            "Training repetition 10\n",
            "Training repetition 1\n",
            "Training repetition 2\n",
            "Training repetition 3\n",
            "Training repetition 4\n",
            "Training repetition 5\n",
            "Training repetition 6\n",
            "Training repetition 7\n",
            "Training repetition 8\n",
            "Training repetition 9\n",
            "Training repetition 10\n",
            "Model 1 (weight decay = 0.1)\n",
            "Training MSE mean: 20.923784446716308\n",
            "Training MSE variance: 3.7158851267656794\n",
            "Validation MSE mean: 23.415653419494628\n",
            "Validation MSE variance: 3.3282430123031737\n",
            "Model 1 (weight decay = 0.5)\n",
            "Training MSE mean: 24.705241012573243\n",
            "Training MSE variance: 8.980323269293294\n",
            "Validation MSE mean: 25.763127517700195\n",
            "Validation MSE variance: 5.397297154119005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "- Looking at the results, we can see that the training MSEs for both models are higher than the validation MSEs, which is a good sign as it indicates that the models are not overfitting. However, the validation MSEs are higher than the training MSEs, which suggests that the models are underfitting to some extent.\n",
        "- Comparing the two models, we can see that Model 1 with weight decay of 0.1 performs better than Model 2 with weight decay of 0.5, as it has lower mean and variance of MSEs for both training and validation datasets. This suggests that a weight decay of 0.1 is more suitable for this particular dataset and model architecture.\n",
        "\n",
        "→ Overall, the results suggest that the models may not be performing well enough to be used for predicting new data, and may need further tuning or refinement."
      ],
      "metadata": {
        "id": "YjtjKeEAs9QC"
      }
    }
  ]
}