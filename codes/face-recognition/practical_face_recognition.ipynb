{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvmJQD0AkQ292YDX/OSGNX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtht2d/deep-learning/blob/main/codes/face-recognition/practical_face_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%autosave 30"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "d8TC5_UZBOZX",
        "outputId": "d146cae4-6681-40b9-9fbd-567088e81b40"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.notebook.set_autosave_interval(30000)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autosaving every 30 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fine-tuning VGG19 for Face Recognition: Analysis of Genuine and Impostor Scores, ROC Curve, and Threshold Optimization**"
      ],
      "metadata": {
        "id": "YAx3qpFjx7jF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Objective**\n",
        "Fine-tune a VGG19 with 70% of the data[1]\n",
        "(7 images of each identity) and then use fc7 output as features (do away with classification head but after training-see MATLAB help for “activations” to see how you can get the outputs of an intermediate layer). Using the remaining 3 images per identity (30% validation, that would be images 8, 9, and 10 for each subject), and cosine similarity between enrollment (first validation image, #8) and verifications (second and third images from validation, images #9 and #10), create genuine and impostor score sets and plot their distributions (histograms) and ROC of these two classes (include AUC) for training and testing subsets [2]\n",
        "\n",
        "Cosine similarity between vesctors X and Y is given by \n",
        "$$\n",
        "cos(\\theta)==\\frac{\\sum{x_i*y_i}}{\\sqrt{\\sum{x^2_i}}*\\sqrt{\\sum{y^2_i}}}\n",
        "$$\n",
        "\n",
        "**Other tasks**:\n",
        "\n",
        "- Use ROC curves or score sets, find the threshold for ≈ 1% FAR on the training set, report the threshold and the corresponding training GAR\n",
        "- Apply that decision threshold to the validation score. Report on the resultig FAR and GAR \n",
        "---\n",
        "[1] AT&T face recognition dataset from https://www.kaggle.com/kasikrit/att-database-of-faces\n",
        "\n",
        "[2]To generate all permutations for genuine and imposter pairs, say for the test subset, assume the first verification2\n",
        "feature vector for subject 1 (enrollment reference) is f1_8. Compare it (using cosine similarity) with the remaining 2\n",
        "feature vectors from subject 1: f1_9, f1_10, and record the cosine similarity scores. Now compare f1_8 with the last 2\n",
        "verification features of subject 2: f2_9, f2_10, and record the cosine similarity scores. Continue until you compare\n",
        "f1_8 with the last 2 verification features of the last subject 40: f40_9, f40_10, and record the cosine similarity scores.\n",
        "Carry out a similar process to generate training genuine and impostor scores.\n",
        "\n"
      ],
      "metadata": {
        "id": "cpCD_vwlwBJh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Purpose** "
      ],
      "metadata": {
        "id": "AULMVlsfwVus"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-tuning VGG19 for Face Recognition: Analysis of Genuine and Impostor Scores using Cosine Similarity and ROC Curve"
      ],
      "metadata": {
        "id": "xODSgVgHxaAm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Feature Extraction: By fine-tuning the VGG19 model and extracting features from the fc7 layer, we obtain a lower-dimensional representation of the images that captures important patterns and discriminative information. This allows us to leverage the pre-trained model's knowledge from a large dataset (ImageNet) and adapt it to our specific task.\n",
        "\n",
        "2. Verification and Identification: By comparing the enrollment image (a reference image) with the verification images using cosine similarity, we can quantify the similarity between these images. This process is commonly used in face recognition or biometric identification systems to determine whether two images belong to the same person (genuine scores) or different people (impostor scores).\n",
        "\n",
        "3. Performance Evaluation: Analyzing the distribution of genuine and impostor scores using histograms provides insights into the separability of the features extracted by the model. A well-performing model should have distinct distributions for genuine and impostor scores, indicating that genuine pairs have higher similarity scores than impostor pairs. This evaluation helps understand the model's ability to discriminate between genuine and impostor samples.\n",
        "\n",
        "    ROC Curve and AUC: The ROC curve is a visual representation of the performance of a binary classification system across different thresholds. It shows the trade-off between the true positive rate (sensitivity) and the false positive rate (1 - specificity). The AUC (Area Under the Curve) summarizes the overall performance of the classifier, where a higher AUC value indicates better discrimination between genuine and impostor scores. The ROC curve and AUC provide a comprehensive evaluation of the model's ability to separate the two classes.\n",
        "\n",
        "By following these steps and evaluating the model's performance using metrics like ROC and AUC, you can assess the effectiveness of the fine-tuned VGG19 model for your specific task, understand the separability of the features, and determine its capability to distinguish between genuine and impostor pairs. This analysis is particularly valuable in applications such as biometric recognition or verification systems, where accurate discrimination between individuals is essential."
      ],
      "metadata": {
        "id": "tSgR9q2h2GKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding the threshold "
      ],
      "metadata": {
        "id": "1_pamaGI2fce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of finding the threshold for approximately 1% False Acceptance Rate (FAR) on the training set and applying it to the validation scores is to assess the performance of the face recognition system at a specific operating point.\n",
        "- False Acceptance Rate (FAR): FAR represents the probability of the system incorrectly accepting an impostor (mismatched) pair as a genuine match. A lower FAR indicates a more secure system, as it means fewer impostor pairs are falsely accepted.\n",
        "\n",
        "- Genuine Acceptance Rate (GAR): GAR represents the probability of the system correctly accepting a genuine (matched) pair. A higher GAR indicates a higher accuracy in recognizing genuine pairs.\n",
        "\n",
        "By finding the threshold for approximately 1% FAR on the training set, we determine the threshold score that achieves a desirable balance between system security and recognition accuracy. This threshold separates the genuine and impostor scores, allowing us to classify them as matches or non-matches.\n",
        "\n",
        "Applying this threshold to the validation scores allows you to evaluate the system's performance on **unseen data**. We can measure the resulting False Acceptance Rate (FAR) and Genuine Acceptance Rate (GAR) on the validation set, which indicates how well the system performs in real-world scenarios.\n",
        "\n",
        "By reporting the threshold and the corresponding training GAR, we provide insights into the system's performance at the specified operating point. Similarly, reporting the resulting FAR and GAR on the validation set helps assess the generalization and effectiveness of the system on new data.\n",
        "\n",
        "Overall, this analysis allows you to fine-tune the system's threshold to achieve a desired balance between security (FAR) and recognition accuracy (GAR) and evaluate its performance on both training and validation data."
      ],
      "metadata": {
        "id": "tIlOFjLK10yu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **II. Methods**"
      ],
      "metadata": {
        "id": "mIHsD35byCt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Fine-tune a VGG19 with 70% of the data1\n",
        "(7 images of each identity) and then use fc7 output as features (do away with classification head\n",
        "but after training-see MATLAB help for “activations” to see how you can get the outputs of an\n",
        "intermediate layer). Using the remaining 3 images per identity (30% validation, that would be\n",
        "images 8, 9, and 10 for each subject), and cosine similarity between enrollment (first validation\n",
        "image, #8) and verifications (second and third images from validation, images #9 and #10),\n",
        "create genuine and impostor score sets and plot their distributions (histograms) and ROC of\n",
        "these two classes (include AUC) for training and testing subsets .2\n",
        "\n",
        "Note: Cosine similarity between vectors X and Y is given by\n",
        "Bonus (up to 15 points, if done correctly): using your ROC curves or score sets, find the\n",
        "threshold for ~1% FAR on the training set, and report the threshold and the corresponding\n",
        "training GAR (5 points). 2-Apply that decision threshold to the validation scores. Report on the\n",
        "resulting FAR and GAR (10 points).\n",
        "Deliverable: Please submit your original individual work in form of a slide deck (describing your\n",
        "results (as requested above) and your observations, plus all your MATLAB (or Python) code and\n",
        "NN models (but not the dataset). Submit everything electronically here via CANVAS ONLY by\n",
        "midnight, Friday, April 28.\n",
        "Please download the AT&T face recognition dataset from https://www.kaggle.com/kasikrit/att-database-of-faces (401\n",
        "subjects with 10 different mugshots for each). Follow MATLAB’s transfer learning example https://\n",
        "www.mathworks.com/help/deeplearning/examples/transfer-learning-using-alexnet.html but use VGG19. Other similar\n",
        "architectures such as ResNet or SqueezeNet are also acceptable. You may carry out the project in Python, if you\n",
        "prefer.\n",
        "To generate all permutations for genuine and imposter pairs, say for the test subset, assume the first verification2\n",
        "feature vector for subject 1 (enrollment reference) is f1_8. Compare it (using cosine similarity) with the remaining 2\n",
        "feature vectors from subject 1: f1_9, f1_10, and record the cosine similarity scores. Now compare f1_8 with the last 2\n",
        "verification features of subject 2: f2_9, f2_10, and record the cosine similarity scores. Continue until you compare\n",
        "f1_8 with the last 2 verification features of the last subject 40: f40_9, f40_10, and record the cosine similarity scores.\n",
        "Carry out a similar process to generate training genuine and impostor scores.\n",
        "Annotations\n"
      ],
      "metadata": {
        "id": "Ny-osfXQunxg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K911_iRnuXuX"
      },
      "outputs": [],
      "source": []
    }
  ]
}